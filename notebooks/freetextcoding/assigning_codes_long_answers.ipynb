{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables coded in this notebook: 18, 1373, 8345 et seq, 8780 et seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pandas as pd, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "exportdate = 20180327\n",
    "projectname = 'repract'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lfdn</th>\n",
       "      <th>external_lfdn</th>\n",
       "      <th>tester</th>\n",
       "      <th>dispcode</th>\n",
       "      <th>lastpage</th>\n",
       "      <th>quality</th>\n",
       "      <th>duration</th>\n",
       "      <th>v_7039</th>\n",
       "      <th>v_7040</th>\n",
       "      <th>v_7041</th>\n",
       "      <th>...</th>\n",
       "      <th>output_mode</th>\n",
       "      <th>javascript</th>\n",
       "      <th>flash</th>\n",
       "      <th>session_id</th>\n",
       "      <th>language</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>ats</th>\n",
       "      <th>datetime</th>\n",
       "      <th>date_of_last_access</th>\n",
       "      <th>date_of_first_mail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>no tester</td>\n",
       "      <td>Completed after break (32)</td>\n",
       "      <td>2138658</td>\n",
       "      <td>NotShown</td>\n",
       "      <td>-1</td>\n",
       "      <td>NotShown</td>\n",
       "      <td>NotShown</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>HTML</td>\n",
       "      <td>NotShown</td>\n",
       "      <td>NotShown</td>\n",
       "      <td>3bb21c1b318e2f6b87557566bdd6b4d9</td>\n",
       "      <td>English</td>\n",
       "      <td>Not cleaned</td>\n",
       "      <td>1515411510</td>\n",
       "      <td>2018-01-08 11:38:30</td>\n",
       "      <td>2018-01-08 13:07:14</td>\n",
       "      <td>0000-00-00 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>no tester</td>\n",
       "      <td>Completed (31)</td>\n",
       "      <td>2138658</td>\n",
       "      <td>NotShown</td>\n",
       "      <td>3805</td>\n",
       "      <td>NotShown</td>\n",
       "      <td>NotShown</td>\n",
       "      <td>NotShown</td>\n",
       "      <td>...</td>\n",
       "      <td>HTML</td>\n",
       "      <td>NotShown</td>\n",
       "      <td>NotShown</td>\n",
       "      <td>fc38f6556787a459c2cc604abf799448</td>\n",
       "      <td>English</td>\n",
       "      <td>Not cleaned</td>\n",
       "      <td>1515667019</td>\n",
       "      <td>2018-01-11 10:36:59</td>\n",
       "      <td>2018-01-11 11:40:24</td>\n",
       "      <td>0000-00-00 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1360 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   lfdn  external_lfdn     tester                    dispcode  lastpage  \\\n",
       "0   106              0  no tester  Completed after break (32)   2138658   \n",
       "1   131              0  no tester              Completed (31)   2138658   \n",
       "\n",
       "    quality  duration    v_7039    v_7040    v_7041         ...           \\\n",
       "0  NotShown        -1  NotShown  NotShown         0         ...            \n",
       "1  NotShown      3805  NotShown  NotShown  NotShown         ...            \n",
       "\n",
       "  output_mode javascript     flash                        session_id language  \\\n",
       "0        HTML   NotShown  NotShown  3bb21c1b318e2f6b87557566bdd6b4d9  English   \n",
       "1        HTML   NotShown  NotShown  fc38f6556787a459c2cc604abf799448  English   \n",
       "\n",
       "       cleaned         ats             datetime  date_of_last_access  \\\n",
       "0  Not cleaned  1515411510  2018-01-08 11:38:30  2018-01-08 13:07:14   \n",
       "1  Not cleaned  1515667019  2018-01-11 10:36:59  2018-01-11 11:40:24   \n",
       "\n",
       "    date_of_first_mail  \n",
       "0  0000-00-00 00:00:00  \n",
       "1  0000-00-00 00:00:00  \n",
       "\n",
       "[2 rows x 1360 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'../../data/{exportdate}{projectname}.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = '../../data/freetext'\n",
    "freetextfiles = os.listdir(basedir)\n",
    "dfs = {file[:-4]:pd.read_csv(f'{basedir}/{file}') for file in freetextfiles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['.DS_S', 'v_11', 'v_1373', 'v_16', 'v_18', 'v_19', 'v_6', 'v_8345etseq', 'v_8780etseq'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leaving this here temporarily merely for reference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_unique_code(df, func, varname):\n",
    "    df[f'{varname}_coded'] = func(df[varname])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "codedir = '../../analysis/freetext'\n",
    "def write_coded(df, varname):\n",
    "    filepath = f'{codedir}/{varname}_coded.csv'\n",
    "    df.to_csv(f'{codedir}/{varname}_coded.csv', index=False)\n",
    "    print(f'File stored at {filepath}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For long entries, we actually want to enable multiple tagging, therefore, we want to produce a long-form DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stuff below is just for the structure - TODO: fill in sensible info..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_var_long(df, index_col, coding_col, partial_df=None):\n",
    "    # assumes input df sorted by index col\n",
    "    new_df = partial_df if partial_df is not None else pd.DataFrame(columns=[\n",
    "        index_col, f'{coding_col}_code'])\n",
    "    min_index = max(partial_df[index_col]) if partial_df is not None else 0\n",
    "    for row in df[[index_col, coding_col]].iterrows():\n",
    "        if row[0] > min_index:\n",
    "            print(row[1][1])\n",
    "            codes = input('Specify codes separated by commas (Code A,Code B,). '\n",
    "                      +'Enter X to quit and return partial frame.\\n'\n",
    "                     ).split(',')\n",
    "            print('\\n')\n",
    "            if codes[0] == 'X':\n",
    "                write_coded(newdf, f'{coding_col}_code')\n",
    "                return new_df.reset_index().drop('index', axis=1)\n",
    "            for code in codes:\n",
    "                new_df = new_df.append(pd.DataFrame({index_col:[row[1][0]],f'{coding_col}_code':[code]}))\n",
    "    write_coded(newdf, f'{coding_col}_{min_index}-{row[0]}_code')\n",
    "    return new_df.reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential Categories:\n",
    "- Practical Problem (Relevance)\n",
    "- Sensible Solution (Plausibility)\n",
    "- Astute Approach (Originality)\n",
    "- NotAnswered (String with no true content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 These practices and artifacts are essential for our work, and are broadly applicable. Their ubiquity often means they are subject to unstated assumptions of their utility. Understanding how others have used them could provide insights into our own work. \n",
      "20 In my experience, framing requirements as a constraint for a creative problem solving process yields better solutions. Any help with establishing and improving such practices will likely help the industry provide better solutions. \n",
      "54 This research addresses a very relevant issue for the industry, it may lead to important practical applications. \n",
      "66 This dilemma occurs constantly in practice: time vs. quality.\n",
      "77 In my opinion we need to share and exchange more information related to the practices that we have been using in order to increase our performance and maturity level.\n",
      "92 Will enable upfront proof and a way to measure in practice. Confidence to the team and the client.\n",
      "107 There is a tension between RE rigour and agile; understanding how this might be addressed in practice is critical for the future of RE\n",
      "119 It is a problem practitioners struggle with\n",
      "121 Use of automation for processing large models really helps practitioners, saving time and allowing them to work more carefully in refinements (rather than on simple issues that would be caught easily by algorithms)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Relevance\n",
    "x = 0\n",
    "for idx, r in enumerate(dfs['v_8345etseq']['reasoning']):\n",
    "    if (re.search(\n",
    "        'practi',r)\n",
    "        ):\n",
    "        print(idx, r)\n",
    "        x +=1 \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(series, regex, idx_only=False):\n",
    "    if idx_only:\n",
    "        return [idx for idx, x in enumerate(series) if re.search(regex, x)]\n",
    "    else:\n",
    "        return [(idx, x) for idx, x in enumerate(series) if re.search(regex, x)]\n",
    "\n",
    "def find_unmatched(series, regexes):\n",
    "    series_idx = {idx for idx, x in enumerate(series)}\n",
    "    matched_idx = set()\n",
    "    for regex in regexes:\n",
    "        matched_idx = matched_idx.union(set(match(series, regex, True)))\n",
    "    return sorted(list(series_idx.difference(matched_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexes = [\n",
    "    # Relevance\n",
    "    '[Pp]roblem|[Cc]halleng|[Ee]xperienc|[Rr]elevan|[Ee]ssential|[Cc]ritical|[Cc]rucial|[Ii]mporta|[Ii]ssue(?!s)|[Cc]oncern|[Dd]ifficult|[Nn]eed(?!s)|(?:^|\\W)[Ww]e\\W|[Ff]undamental|[Dd]ilemma',\n",
    "    # Plausibility\n",
    "    '[Cc]ould|[Mm]ight|[Hh]elp(s|ful)?(?!\\w)|[Ii]mproves?(?!m)|(?<!\\sto\\s)better',\n",
    "    # Originality\n",
    "    'literature|gap|interesting'\n",
    "]\n",
    "len(find_unmatched(dfs['v_8345etseq']['reasoning'], regexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "A learning-by-example method is one of the most efficient tools allowing for decreasing the uncertainty in the future.\n",
      "Benchmarks are the start of everything.\n",
      "A many more automatical methods shall support and ease the work of RE. Especially for standardised requirements, security, safety, traceability analysis,etc. \n",
      "non-functional reqs have the biggest impact on architecture and may not be left aside \n",
      "it will give me good reasones for RE that managers will understand\n",
      "aren't they connected?\n",
      "I'm working in agile development environments. This items affects my work significantly.\n",
      "Because of the conflict between complete requirements and fast requirements.\n",
      "A lot of regulations are contradictory, it is good to have an overview for decision making\n",
      "I think that communication in general is a success factor of a project; good communication drives to the right goals.\n",
      "Green field happens from time to time; incremental improvements are very common. Change requests occur frequently\n",
      "Non-functional requirements do not always get the attention they deserve.  Correlating understanding of non-functional requirements to project success would be of interest. \n",
      "To many goverment project get out of budget and time and in many cases the supplier just want to earn money and not focus on customer needs.\n",
      "Product managers in general and the product owner role in the agile context is misintrerpreted, poorly performed. many times by software managers with no expertice in the specific application domain. \n",
      "Systems (including vehicles) are becoming more autonomous and adaptive, and there is a lot to be done here.\n",
      "To avoid last minute surprise at end. \n",
      "This is an area and a topic I recognize from my work and the environment I am working in.\n",
      "it is a great way of tracking customer satisfaction and its impacts\n",
      "Without a traceability stratergy an organisation will not be in a position to implement any project that delivers on their planned stratergy or visions.\n",
      "Demand in growing systems to guarantee traceability \n",
      "um einen sichereen Überblick über die beschriebenen Ablaüfe zu erhalten\n",
      "User developer communication is usually very complcated because they come from different domains and focus on different goals and details.\n",
      "I strongly believe that requirements elicitation should be automated as much as possible to get the process standardized and avoid major mistakes.\n",
      "To understand more from the interview also to make sure the interviewee is the right person \n",
      "companies and businesses still use a high amount of textual documents which can be used for RE purposes\n",
      "More and more software is cinnected with others, big projects reuslt and are not easy to define and manage\n",
      "Will enable upfront proof and a way to measure in practice. Confidence to the team and the client.\n",
      "It can antecipate risks in the decision making and eventually avoid to elect unadequate requirements to be implemented\n",
      "prioritizing requirements is one of the most challenging tasks for REs \n",
      "The conflict point is IT security - one party wants simple access, the other party wants to close the door with seven locks.\n",
      "I feel that risk management is not always systematically performed, and it's results flown into requirements. A more integrated RM/RE approach would be useful to force structured activity performing and automate results conversion to requirements/actions.\n",
      "Writing specs and requirements needs a big amount of time in projects. If you have a good spec at the end why not using the whole spec or parts again in case there is a good approach. Often a good, existing spec is taken, but not according a real concept.\n",
      "one of the most insidious defects in software is a system being in an illegal state.  hard to find in testing, it tends to appear randomly.\n",
      "Visual representation is worth a 1000 words, and nobody wants to read 1000 words. Requirements evolve and this is often missed.\n",
      "Provide a lead in architecture definition \n",
      "To avoid rework and not-fit-for-purpose solutions on delivery\n",
      "The people who pay the bills don't always consider all the impact changes can make. having a way to prove what you are recommending is worth while.\n"
     ]
    }
   ],
   "source": [
    "for idx, x in enumerate(dfs['v_8345etseq']['reasoning']):\n",
    "    if idx in find_unmatched(dfs['v_8345etseq']['reasoning'], regexes):\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedure:\n",
    "- Refine Regex to the point where further refinement would lead to drastical overfitting\n",
    "- Assign Reasoning Tags via Automation\n",
    "- Find Answers with no Tags and Assign Manually\n",
    "- Verify all tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tum]",
   "language": "python",
   "name": "conda-env-tum-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
