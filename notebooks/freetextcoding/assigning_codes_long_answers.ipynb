{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables coded in this notebook: 18, 1373, 8345 et seq, 8780 et seq\n",
    "\n",
    "NB: Here, multiple tags should be allowed, so we need long-form DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Maybe work out satisfiers, dissatisfiers and excitement factors (or what were they called?) as RE research relevance requirements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pandas as pd, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exportdate = 20180327\n",
    "projectname = 'repract'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lfdn</th>\n",
       "      <th>external_lfdn</th>\n",
       "      <th>tester</th>\n",
       "      <th>dispcode</th>\n",
       "      <th>lastpage</th>\n",
       "      <th>quality</th>\n",
       "      <th>duration</th>\n",
       "      <th>v_7039</th>\n",
       "      <th>v_7040</th>\n",
       "      <th>v_7041</th>\n",
       "      <th>...</th>\n",
       "      <th>output_mode</th>\n",
       "      <th>javascript</th>\n",
       "      <th>flash</th>\n",
       "      <th>session_id</th>\n",
       "      <th>language</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>ats</th>\n",
       "      <th>datetime</th>\n",
       "      <th>date_of_last_access</th>\n",
       "      <th>date_of_first_mail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>no tester</td>\n",
       "      <td>Completed after break (32)</td>\n",
       "      <td>2138658</td>\n",
       "      <td>NotShown</td>\n",
       "      <td>-1</td>\n",
       "      <td>NotShown</td>\n",
       "      <td>NotShown</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>HTML</td>\n",
       "      <td>NotShown</td>\n",
       "      <td>NotShown</td>\n",
       "      <td>3bb21c1b318e2f6b87557566bdd6b4d9</td>\n",
       "      <td>English</td>\n",
       "      <td>Not cleaned</td>\n",
       "      <td>1515411510</td>\n",
       "      <td>2018-01-08 11:38:30</td>\n",
       "      <td>2018-01-08 13:07:14</td>\n",
       "      <td>0000-00-00 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>no tester</td>\n",
       "      <td>Completed (31)</td>\n",
       "      <td>2138658</td>\n",
       "      <td>NotShown</td>\n",
       "      <td>3805</td>\n",
       "      <td>NotShown</td>\n",
       "      <td>NotShown</td>\n",
       "      <td>NotShown</td>\n",
       "      <td>...</td>\n",
       "      <td>HTML</td>\n",
       "      <td>NotShown</td>\n",
       "      <td>NotShown</td>\n",
       "      <td>fc38f6556787a459c2cc604abf799448</td>\n",
       "      <td>English</td>\n",
       "      <td>Not cleaned</td>\n",
       "      <td>1515667019</td>\n",
       "      <td>2018-01-11 10:36:59</td>\n",
       "      <td>2018-01-11 11:40:24</td>\n",
       "      <td>0000-00-00 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1360 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   lfdn  external_lfdn     tester                    dispcode  lastpage  \\\n",
       "0   106              0  no tester  Completed after break (32)   2138658   \n",
       "1   131              0  no tester              Completed (31)   2138658   \n",
       "\n",
       "    quality  duration    v_7039    v_7040    v_7041         ...           \\\n",
       "0  NotShown        -1  NotShown  NotShown         0         ...            \n",
       "1  NotShown      3805  NotShown  NotShown  NotShown         ...            \n",
       "\n",
       "  output_mode javascript     flash                        session_id language  \\\n",
       "0        HTML   NotShown  NotShown  3bb21c1b318e2f6b87557566bdd6b4d9  English   \n",
       "1        HTML   NotShown  NotShown  fc38f6556787a459c2cc604abf799448  English   \n",
       "\n",
       "       cleaned         ats             datetime  date_of_last_access  \\\n",
       "0  Not cleaned  1515411510  2018-01-08 11:38:30  2018-01-08 13:07:14   \n",
       "1  Not cleaned  1515667019  2018-01-11 10:36:59  2018-01-11 11:40:24   \n",
       "\n",
       "    date_of_first_mail  \n",
       "0  0000-00-00 00:00:00  \n",
       "1  0000-00-00 00:00:00  \n",
       "\n",
       "[2 rows x 1360 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'../../data/{exportdate}{projectname}.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = '../../data/freetext'\n",
    "freetextfiles = os.listdir(basedir)\n",
    "dfs = {file[:-4]:pd.read_csv(f'{basedir}/{file}') for file in freetextfiles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['.DS_S', 'v_11', 'v_1373', 'v_16', 'v_18', 'v_19', 'v_6', 'v_8345etseq', 'v_8780etseq'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "codedir = '../../analysis/freetext'\n",
    "def write_coded(df, varname, prelim=False):\n",
    "    filepath = f'{codedir}/{varname}_coded{\"_prelim\" if prelim else \"\"}.csv'\n",
    "    df.to_csv(filepath, index=False)\n",
    "    print(f'File stored at {filepath}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General Procedure:\n",
    "- Refine Regex to the point where further refinement would lead to drastical overfitting\n",
    "- Assign Reasoning Tags via Automation\n",
    "- Find Answers with no Tags and Assign Manually\n",
    "- Verify all tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_reasoning_tags(df, regexes):\n",
    "    newdf = pd.DataFrame(columns=list(df.columns.values) + ['Tag'])\n",
    "    for k,v in regexes.items():\n",
    "        matches = pd.DataFrame([list(row[1])+[k] for row in df.iterrows() if re.search(v, row[1][-1])], \n",
    "                               columns=list(df.columns.values) + ['Tag'])\n",
    "        newdf = newdf.append(matches)\n",
    "    newdf = newdf.append(pd.DataFrame([list(row[1])+['NotAnswered'] for row in df.iterrows() if len(row[1][-1]) < 5], \n",
    "                               columns=list(df.columns.values) + ['Tag']))\n",
    "    newdf = newdf.sort_values(['PaperID', 'lfdn'])\n",
    "    newdf = newdf.append(pd.DataFrame([list(row[1])+[''] for row in df.iterrows() \n",
    "                                       if (row[1][0],row[1][1]) not in list(zip(newdf.PaperID.values, newdf.lfdn.values))], \n",
    "                               columns=list(df.columns.values) + ['Tag']))\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unmatched(df):\n",
    "    return df[df.Tag == ''][['PaperID', 'lfdn', 'reasoning']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper\n",
    "def minitest(df, regex):\n",
    "    x = 0\n",
    "    for idx, r in enumerate(df):\n",
    "        if (re.search(\n",
    "            regex,r)\n",
    "            ):\n",
    "            print(idx, r)\n",
    "            x +=1 \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positive Reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive Reasoning Categories:\n",
    "- Practical Problem (Relevance) / Characteristics of the Problem\n",
    "- Sensible Solution (Plausibility) / Characteristics of the Solution\n",
    "- Astute Approach (Originality) / Characteristics of the Solution (more generic than Plausibility)\n",
    "- NotAnswered (String with no true content)\n",
    "\n",
    "With Reference to:\n",
    "- experience (explicit reference to personal experience)\n",
    "- opinion    (explicit reference to personal judgment)\n",
    "- perception (implicit - people making statements of fact without reference to their source - euphemism for 'no arguments presented' - not explicitly tagged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexes = {\n",
    "    'reason:relevance': \n",
    "        '[Pp]roblem|[Cc]halleng|[Ee]xperienc|[Rr]elevan|[Ee]ssential|[Cc]ritical|[Cc]rucial|[Ii]mporta|[Ii]ssue(?!s)|[Cc]oncern|[Dd]ifficult|[Nn]eed(?!s)|(?:^|\\W)[Ww]e\\W|[Ff]undamental|[Dd]ilemma',\n",
    "    'reason:plausibility': \n",
    "        '[Cc]ould|[Mm]ight|[Hh]elp(s|ful)?(?!\\w)|[Ii]mproves?(?!m)|(?<!\\sto\\s)better',\n",
    "    'reason:originality': \n",
    "        'literature|gap|interesting',\n",
    "    'source:experience': \n",
    "        '(?:^|\\W)my\\W.*?(?:experience|work)',\n",
    "    'source:opinion': \n",
    "        '(?:^|\\W)my\\Wopinion(?!:)|[Bb]eliev|[Tt]hink|[Ff]eel',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PaperID</th>\n",
       "      <th>lfdn</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>Tag</th>\n",
       "      <th>level_1</th>\n",
       "      <th>level_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>116</td>\n",
       "      <td>Aligning requirements to regulatory standards ...</td>\n",
       "      <td>reason:relevance</td>\n",
       "      <td>reason</td>\n",
       "      <td>relevance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>152</td>\n",
       "      <td>.</td>\n",
       "      <td>NotAnswered</td>\n",
       "      <td>NotAnswered</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>94</td>\n",
       "      <td>In order to gain a better understanding from t...</td>\n",
       "      <td>reason:plausibility</td>\n",
       "      <td>reason</td>\n",
       "      <td>plausibility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>110</td>\n",
       "      <td>Ambiguities are a critical source of issues. A...</td>\n",
       "      <td>reason:relevance</td>\n",
       "      <td>reason</td>\n",
       "      <td>relevance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>110</td>\n",
       "      <td>Ambiguities are a critical source of issues. A...</td>\n",
       "      <td>reason:plausibility</td>\n",
       "      <td>reason</td>\n",
       "      <td>plausibility</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PaperID lfdn                                          reasoning  \\\n",
       "0       2  116  Aligning requirements to regulatory standards ...   \n",
       "0       5  152                                                  .   \n",
       "0       8   94  In order to gain a better understanding from t...   \n",
       "1       9  110  Ambiguities are a critical source of issues. A...   \n",
       "1       9  110  Ambiguities are a critical source of issues. A...   \n",
       "\n",
       "                   Tag      level_1       level_2  \n",
       "0     reason:relevance       reason     relevance  \n",
       "0          NotAnswered  NotAnswered                \n",
       "0  reason:plausibility       reason  plausibility  \n",
       "1     reason:relevance       reason     relevance  \n",
       "1  reason:plausibility       reason  plausibility  "
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postags = assign_reasoning_tags(dfs['v_8345etseq'], regexes)\n",
    "postags['level_1'], postags['level_2'] = list(zip(*[tag.split(':') if len(tag.split(':')) > 1 \n",
    "                                                 else tag.split(':') + ['']\n",
    "                                          for tag in postags.Tag \n",
    "                                          ]))\n",
    "postags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File stored at ../../analysis/freetext/v_8345etseq_coded_prelim.csv.\n"
     ]
    }
   ],
   "source": [
    "write_coded(postags[postags.columns.values[:-2]], 'v_8345etseq', prelim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level_1</th>\n",
       "      <th>level_2</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NotAnswered</th>\n",
       "      <th></th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">reason</th>\n",
       "      <th>originality</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plausibility</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relevance</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">source</th>\n",
       "      <th>experience</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opinion</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Tag\n",
       "level_1     level_2          \n",
       "                           31\n",
       "NotAnswered                 1\n",
       "reason      originality     5\n",
       "            plausibility   34\n",
       "            relevance      63\n",
       "source      experience      6\n",
       "            opinion        12"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postags.groupby(['level_1', 'level_2']).count()[['Tag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A learning-by-example method is one of the most efficient tools allowing for decreasing the uncertainty in the future.',\n",
       " 'Benchmarks are the start of everything.',\n",
       " 'A many more automatical methods shall support and ease the work of RE. Especially for standardised requirements, security, safety, traceability analysis,etc. ',\n",
       " 'non-functional reqs have the biggest impact on architecture and may not be left aside ',\n",
       " 'it will give me good reasones for RE that managers will understand',\n",
       " \"aren't they connected?\",\n",
       " 'Because of the conflict between complete requirements and fast requirements.',\n",
       " 'A lot of regulations are contradictory, it is good to have an overview for decision making',\n",
       " 'Green field happens from time to time; incremental improvements are very common. Change requests occur frequently',\n",
       " 'Non-functional requirements do not always get the attention they deserve.  Correlating understanding of non-functional requirements to project success would be of interest. ',\n",
       " 'To many goverment project get out of budget and time and in many cases the supplier just want to earn money and not focus on customer needs.',\n",
       " 'Product managers in general and the product owner role in the agile context is misintrerpreted, poorly performed. many times by software managers with no expertice in the specific application domain. ',\n",
       " 'Systems (including vehicles) are becoming more autonomous and adaptive, and there is a lot to be done here.',\n",
       " 'To avoid last minute surprise at end. ',\n",
       " 'it is a great way of tracking customer satisfaction and its impacts',\n",
       " 'Without a traceability stratergy an organisation will not be in a position to implement any project that delivers on their planned stratergy or visions.',\n",
       " 'Demand in growing systems to guarantee traceability ',\n",
       " 'um einen sichereen Überblick über die beschriebenen Ablaüfe zu erhalten',\n",
       " 'User developer communication is usually very complcated because they come from different domains and focus on different goals and details.',\n",
       " 'To understand more from the interview also to make sure the interviewee is the right person ',\n",
       " 'companies and businesses still use a high amount of textual documents which can be used for RE purposes',\n",
       " 'More and more software is cinnected with others, big projects reuslt and are not easy to define and manage',\n",
       " 'Will enable upfront proof and a way to measure in practice. Confidence to the team and the client.',\n",
       " 'It can antecipate risks in the decision making and eventually avoid to elect unadequate requirements to be implemented',\n",
       " 'The conflict point is IT security - one party wants simple access, the other party wants to close the door with seven locks.',\n",
       " 'Writing specs and requirements needs a big amount of time in projects. If you have a good spec at the end why not using the whole spec or parts again in case there is a good approach. Often a good, existing spec is taken, but not according a real concept.',\n",
       " 'one of the most insidious defects in software is a system being in an illegal state.  hard to find in testing, it tends to appear randomly.',\n",
       " 'Visual representation is worth a 1000 words, and nobody wants to read 1000 words. Requirements evolve and this is often missed.',\n",
       " 'Provide a lead in architecture definition ',\n",
       " 'To avoid rework and not-fit-for-purpose solutions on delivery',\n",
       " \"The people who pay the bills don't always consider all the impact changes can make. having a way to prove what you are recommending is worth while.\"]"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(get_unmatched(postags).reasoning.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO for positive reasoning\n",
    "- add/check tags manually in separate file\n",
    "- do count analysis on final file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lack of Practical Relevance (problem)\n",
    "- Approach too theoretical (solution)\n",
    "- Domain too specialized (solution)\n",
    "-...\n",
    "\n",
    "Also:\n",
    "- Rejection of the assumption contained in the question (e.g., 'it's not a lower rating...')\n",
    "\n",
    "Observation: Practitioners are much more specific when they state what they dislike about research than when they state what they like about research.\n",
    "\n",
    "Some answers are so specific that they can only be properly understood when taking a look at the rated summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB: The regex have gotten a little ugly and need cleanup/refactoring.\n",
    "\n",
    "At this point, they are likely overinclusive..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb some refer to problem some to solution some to question itself\n",
    "negation = \"(?:n'?t|[Nn]ot?)\\W\"\n",
    "negexes = {\n",
    "    # not that 'not important' refers to absolute and relative (=prioritization) importance reasonings\n",
    "    'reason:notimportant': ('[Nn]ot?\\W.{,50}(?:impor|relev|need|necess|frequ)|'\n",
    "                    + '[Dd]istract|decr.*?relev|[Nn]ot?\\W.{,20}(priori|essent)|not.*?big.*?prob'),\n",
    "    'reason:notefficient': '[Ee]ffort',\n",
    "    'reason:notinteresting':  '(?:[Nn]ot?\\W.{,10}|un)interest',\n",
    "    # not that 'not convincing' statements are quite diffuse - critique of assumptions, critique of procedures, ...\n",
    "    'reason:notconvincing': \n",
    "                (\"(?:n't|[Nn]ot?)\\W.{,10}?(?:conv|impr)|[Nn]ot?\\W.{,30}?(help|use)|(?:n'?t|[Nn]ot?)\\W.{,10}sense|\"\n",
    "                    +\"pointless|worse|harm|waste|fail|simplistic|obscure|[Ii]mpractical|[Nn]ot?\\W.*?good|(?:(?:[Cc]a|[Dd]o)n'?t|[Nn]ot?)\\W.{,10}work|\"\n",
    "                    +\"(?:[Nn]ot?\\W|[Dd]on'?t|[Cc]an'?t|[Cc]an\\s?not).{,30}(?:value|benefit)\"),\n",
    "    'reason:notrealistic': '[Tt]o.{,5}(?:theoretic|acad)|skill|scenario|real-w',\n",
    "    'reason:toocomplicated': \"(?:not\\W|n't).*?\\Wund|[Tt]o.{,5}technical\", # ie not understood\n",
    "    'reason:toovague': \"[Ff]luffy|don't know.*?use|not.*?understood\",\n",
    "    'reason:toosubjective': '[Ss]ubjecti',\n",
    "    'reason:notoriginal': 'already',\n",
    "    'reason:toospecialized': '[Tt]o.{,10}specif|particular|special.*?domain|limit|should.*?wider|narrow', \n",
    "    'reason:respondentattitude': 'attitude',\n",
    "    'rejection:ratingnotnegative': 'not?\\W.*?lower', \n",
    "    'rejection:questionnotunderstood': 'not?\\W.*?underst.*?quest|Sorry'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PaperID</th>\n",
       "      <th>lfdn</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>Tag</th>\n",
       "      <th>level_1</th>\n",
       "      <th>level_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>no one cares 'how' you developed, just that yo...</td>\n",
       "      <td>reason:notconvincing</td>\n",
       "      <td>reason</td>\n",
       "      <td>notconvincing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>Document driven approaches are decreasing in r...</td>\n",
       "      <td>reason:notimportant</td>\n",
       "      <td>reason</td>\n",
       "      <td>notimportant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PaperID lfdn                                          reasoning  \\\n",
       "0       4   30  no one cares 'how' you developed, just that yo...   \n",
       "0       5   35  Document driven approaches are decreasing in r...   \n",
       "\n",
       "                    Tag level_1        level_2  \n",
       "0  reason:notconvincing  reason  notconvincing  \n",
       "0   reason:notimportant  reason   notimportant  "
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negtags = assign_reasoning_tags(dfs['v_8780etseq'], negexes)\n",
    "negtags['level_1'], negtags['level_2'] = list(zip(*[tag.split(':') if len(tag.split(':')) > 1 \n",
    "                                                 else tag.split(':') + ['']\n",
    "                                          for tag in negtags.Tag \n",
    "                                          ]))\n",
    "negtags.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File stored at ../../analysis/freetext/v_8780etseq_coded_prelim.csv.\n"
     ]
    }
   ],
   "source": [
    "write_coded(negtags[negtags.columns.values[:-2]], 'v_8780etseq', prelim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level_1</th>\n",
       "      <th>level_2</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NotAnswered</th>\n",
       "      <th></th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">reason</th>\n",
       "      <th>notconvincing</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notefficient</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notimportant</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notinteresting</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notoriginal</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notrealistic</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>respondentattitude</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toocomplicated</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toospecialized</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toosubjective</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toovague</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">rejection</th>\n",
       "      <th>questionnotunderstood</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ratingnotnegative</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Tag\n",
       "level_1     level_2                   \n",
       "                                    36\n",
       "NotAnswered                          1\n",
       "reason      notconvincing           26\n",
       "            notefficient             5\n",
       "            notimportant            18\n",
       "            notinteresting           5\n",
       "            notoriginal              3\n",
       "            notrealistic             7\n",
       "            respondentattitude       1\n",
       "            toocomplicated           6\n",
       "            toospecialized           7\n",
       "            toosubjective            1\n",
       "            toovague                 3\n",
       "rejection   questionnotunderstood    3\n",
       "            ratingnotnegative        1"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negtags.groupby(['level_1', 'level_2']).count()[['Tag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['If we could see how ambiguous documentation can affect a software project, perhaps software industry could be persuaded to do a better requirements documentation.',\n",
       " 'because it can benefit the reusability of solutions',\n",
       " 'Quantitative analysis of usability is confusing and misleding',\n",
       " 'not for all, some is, some not.',\n",
       " \"I selected the option 'Worthwhile', so I consider it important.\",\n",
       " 'Form specification would solve a lot of problem, however I do not know any industry project which could specifiy the system with formal language. Yes we need a more dynamic way of specifiying our systems',\n",
       " 'As a practioner, I prefer learning about the answers than learning about the problems we all know we have.',\n",
       " 'In my experience, most modeling language research never goes beyond the PhD lab. It may be valuable eventually, but this needs application before asserting its utility.',\n",
       " 'creativity ist nicht der entscheidende Punkt, eher geht es um Kenntnis der Probreme eines Anwendungsbereichs',\n",
       " 'i am not clear not this',\n",
       " 'Too many different personal opinions, different standards in different industries',\n",
       " 'To me it is unclear how the self-understanding of product managers is a beneficial input for the education of product managers. More relevant would be the problems that hinder product manager from doing their work effectively.',\n",
       " 'Better to have involving than from paper work',\n",
       " 'It is not clear to me how simple  data  (whatever that means) can help to create requirements or just recommendations.',\n",
       " 'Sounds more like a specialised piece of analytics research for which is a field in its own right. We have specialists that do this work.',\n",
       " 'The product that we deliver is not a web page.',\n",
       " 'Usually, one mind is the head of the project. This person gives the direction, thus s/he is the only person which needs to align the different between the requirements and the customer needs.',\n",
       " 'I consider that domain professionals are better placed to recommend and oversight the rehabilitation process (human interactions still important I guess ;)',\n",
       " 'keyword AI: how can requirements for AIs be defined?',\n",
       " 'the level at which architects work and the magnitude of software system projects does not always justify the means',\n",
       " 'Each project is very different and is impacted by a multitude of variables that are not consistent across all industry domains and corporation operations. This would make it very diificult to design an algorithm that can reliably predict integration bugs',\n",
       " 'The industry has never go too far from natural language specifications. ',\n",
       " 'automatic extracted requirement needs to reviewed again by person.',\n",
       " 'The prerequisites from applying the investigated method are rarely met. It is like an investigation  Given the assumption that humans can fly, what would be the effect on CO_2 polution ',\n",
       " 'Because the regulations are changed',\n",
       " \"It's a work that human beings can do without a high technology level involved.\",\n",
       " 'Advances in technology and changes in society are rapid, systems need to be able to keep up with it.',\n",
       " 'The decision of which feature next is not based on uncertainty but on an economic or technical risk view as e.g. in WSJF.',\n",
       " \"It's always important to have a clear prioritization mechanism so we don't get additional conflicts and frustrations\",\n",
       " \"Availability is only one of many NFRs, and I don't see why this one should receive special attention.\",\n",
       " 'For us it is important to continiously check if the requirements are still up to date. ',\n",
       " 'Agile approach, I do not see this as applicable (at the moment) in the automotive industry ',\n",
       " 'first things first. Big-bang integration are history in an agile world. Design and architecture have major impact on complexity.',\n",
       " 'Blablabla ',\n",
       " \"it's important if one is searching for a good tool to do RE. I did this once and it was difficult.\"]"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(get_unmatched(negtags).reasoning.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 Understandability of requirements is not the biggest problem in RE.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minitest(dfs['v_8780etseq']['reasoning'], \"not.*?big.*?prob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no one cares 'how' you developed, just that you have your specifications. there are also too many personalities that no one would use it anyway\n",
      "Document driven approaches are decreasing in relevance. \n",
      "If we could see how ambiguous documentation can affect a software project, perhaps software industry could be persuaded to do a better requirements documentation.\n",
      "I don't know what techniques will be used\n",
      "because it can benefit the reusability of solutions\n",
      "If an analyst can communicate well with domain experts and users, if he can analyze what he heard and organize his own thoughts logically, he can create a domain model. I am not sure I trust an analyst who needs a method to explain him how to do it...\n",
      "it is limited to  a company , if it would be a survey with many companies it would have more validity\n",
      "No need in my environment.\n",
      "Assumes that high-level goals and requirements are hierarcical. They are not in practice. They are many-to-many and attempts to make them hierarchical make things worse.\n",
      "Traceability is not really important or used in all the companies that I worked at. Also, using a small data set does not sound interesting.\n",
      "Quantitative analysis of usability is confusing and misleding\n",
      "not for all, some is, some not.\n",
      "I selected the option 'Worthwhile', so I consider it important.\n",
      "I am not convinced that documenting inspections is a good way to improve defect discovering.\n",
      "Most engineers are bad writers but good readers. Most projects use specific wocabulary. Automated analysis would do more harm than good.\n",
      "There should be a wider approach to support impact analysis.\n",
      "I'm not sure how I would apply this research as I don't understand what the outcome would be.\n",
      "Form specification would solve a lot of problem, however I do not know any industry project which could specifiy the system with formal language. Yes we need a more dynamic way of specifiying our systems\n",
      "Very special for domain and land. Genral applicability of results not sure\n",
      "It is very difficult to define a structure to describe requirements that could make possible to extract feature models. The effort to do that would be high, and practitioners would use this this to break the problem in small parts, in order to understand \n",
      "As a practioner, I prefer learning about the answers than learning about the problems we all know we have.\n",
      "In my experience, to use cross-references they would not help me to identitfy conflicting requirements, because to the industries or customer that is not importat, they focus to get finished their project. There are too little bit places that they matter \n",
      "Not sure if we need a dedicated analyst to actually validate the output of the tool \n",
      "impractical as old solutions may not apply or be hard to find.\n",
      "In my experience, most modeling language research never goes beyond the PhD lab. It may be valuable eventually, but this needs application before asserting its utility.\n",
      "creativity ist nicht der entscheidende Punkt, eher geht es um Kenntnis der Probreme eines Anwendungsbereichs\n",
      "i am not clear not this\n",
      "It does not make sense for me. \n",
      "Too many different personal opinions, different standards in different industries\n",
      "relatively uninteresting\n",
      "To me it is unclear how the self-understanding of product managers is a beneficial input for the education of product managers. More relevant would be the problems that hinder product manager from doing their work effectively.\n",
      "Better to have involving than from paper work\n",
      "It looks as management problem, wrong person on wrong place and and doesn't general improve the requirement process. \n",
      "Too technical, I even do not know what u are talking about. We as REs do not take to hard into consideration what technology to be used nor do we prefer certain tools. As well: we think in requirements and not in solutions\n",
      "Sorry, I don't understand well this topic... If the machine is a project, then it should have this experiment to test its efectiveness\n",
      "Didn't really understand what was going on here.\n",
      "It is not clear to me how simple  data  (whatever that means) can help to create requirements or just recommendations.\n",
      "Sounds more like a specialised piece of analytics research for which is a field in its own right. We have specialists that do this work.\n",
      "I think it might be a waste of time and a result that is not applicable to any greater extent. But who knows?\n",
      "The product that we deliver is not a web page.\n",
      "Fluffy.\n",
      "Usually, one mind is the head of the project. This person gives the direction, thus s/he is the only person which needs to align the different between the requirements and the customer needs.\n",
      "It's too subjective\n",
      "I consider that domain professionals are better placed to recommend and oversight the rehabilitation process (human interactions still important I guess ;)\n",
      "This is a very narrow topic (on its own in is worthwile) ... however is there a special method for eliciting and modeling needed? Why not take an existing on?\n",
      "keyword AI: how can requirements for AIs be defined?\n",
      "the level at which architects work and the magnitude of software system projects does not always justify the means\n",
      "It's not a real lower rating. I only voted in a higher way the papers that I would read first considering to have a  short time  at job. I didn't rate some papers for that too but I think that all of them could be really interesting.\n",
      "Requirements brainstorming sessions are not that frequent and, furthermore, I do not believe that most interesting ideas in brainstorming necessarily come from people with a knowledge of the domain. Ideas in brainstorming come from exchanging between peop\n",
      "Each project is very different and is impacted by a multitude of variables that are not consistent across all industry domains and corporation operations. This would make it very diificult to design an algorithm that can reliably predict integration bugs\n",
      "I dont see a value in designing new notations with novices.  Either we train them in a specific notation or we let them use their one intuitive notation and translate in a model language. \n",
      "The industry has never go too far from natural language specifications. \n",
      "automatic extracted requirement needs to reviewed again by person.\n",
      "I have no interest in app store feedback.  Seem a very tenious link to RE.\n",
      "Too case-specific\n",
      "not relevant for my work\n",
      "The prerequisites from applying the investigated method are rarely met. It is like an investigation  Given the assumption that humans can fly, what would be the effect on CO_2 polution \n",
      "It is  not necessary\n",
      "Because the regulations are changed\n",
      "This is not clearly understood to me\n",
      "I don't think evolution prediction could be reduced to a metric-based approach. This could be too simplistic for a complex phenomenon.\n",
      "This seems restrictive. I am not interested in data supply chains.\n",
      "I can't see the value of such a case study\n",
      "Not so important to all resources.\n",
      "Students do not yey have the skills to contribuye meaningfully.\n",
      "Real scenario would provide best results and conclusions\n",
      "Preferring experiment for skilled people\n",
      "because sometimes is not easy understand structured requirements models. processes and images, if they are simple, are easy to understand\n",
      "Don't know what social adaptation is and how is it related to real-word software development.\n",
      "Detailed priorization methods a Never Applied in practice because effort much too high. Usually it is pretty fast and easy, to decide the implementation order of the reqs. Through personal communication e.g. in a Meeting with some engineers and managers \n",
      "Dont see the big benefit because I see the consistency less as a method topic than a resource topic. Ofen too less capacity is available to keep consistency. \n",
      "The easiest answer is, that this doesn't affect my daily business and i'm sure that there are already approaches existing.\n",
      "I cannot see how such a study would benefit me and the area in which I work.\n",
      "Distraction from the goal\n",
      "I am not sure of how this can help an analyst working on a commercial application.\n",
      "It's a work that human beings can do without a high technology level involved.\n",
      "In my opinion, this will not work. Additionally, this leads to promises which will nto be satisfied.\n",
      "Sorry, I don't know...\n",
      "feedback loops in CR systems are already common practice\n",
      "Advances in technology and changes in society are rapid, systems need to be able to keep up with it.\n",
      ".\n",
      "i cannot imagine any sensefull use of possible results in the reality of software engineering\n",
      "NFRs are not that important after all and current prosa-based methods are sufficient.  Modeling language for NFRRs is too much!\n",
      "The decision of which feature next is not based on uncertainty but on an economic or technical risk view as e.g. in WSJF.\n",
      "I do not understand the question.  No idea/No opinion  option was not available.\n",
      "Not too relevant in my industry.\n",
      "for me it's too general a piece of research with no use for me. \n",
      "It's always important to have a clear prioritization mechanism so we don't get additional conflicts and frustrations\n",
      "Do not understand the he problem with safety requirement.\n",
      "Availability is only one of many NFRs, and I don't see why this one should receive special attention.\n",
      "These studies already exist\n",
      "For us it is important to continiously check if the requirements are still up to date. \n",
      "uncertainty on uncertainty - not a good approach\n",
      "Worthwile to research, but the approaches might be extremely different in each company or engineering environment. If standard patterns can be identified, it could be very interesting from a Test and QM perspective, but not really essential to RM. \n",
      "Traceability is not a high-priority activity in Requirements Engineering.\n",
      "I do not see in practice use case specifications as software artifacts to which software engineers return to perform changes, normally they are used just once as initial specifications\n",
      "Because it is assessing the usefulness of a particular diagramming tool, and in particular with students. It would be more relevant assessing the modeling capabilities of a diagramming notation, whatsoever the tool, by practitioners with expertise on diag\n",
      "Agile approach, I do not see this as applicable (at the moment) in the automotive industry \n",
      "The subject looks obscure to me, so the benefits for performing such research \n",
      "probably because of my own attitude.\n",
      "Not interesting for my working environment.\n",
      "Formal specifications (that I've worked extensively with myself in an industrial context) are usually way too advanced compared to the real-world problems that most product managers struggle with\n",
      "pointless. Clip on modules to a complex set of goals cannot be orchestrated to be as robust as the original goal\n",
      "This seems an overkill and the expected outcome does not appear to be justifying the efforts.\n",
      "huge effort and need a lot of time, better approaches are available\n",
      "This oinly applies to a small (significant) sector of BAs - spend your efforts on helping more BAs!\n",
      "interesting, but sounds too theoretical for real project life\n",
      "first things first. Big-bang integration are history in an agile world. Design and architecture have major impact on complexity.\n",
      "Cannot be representative because it is highly depending on experience of the reader\n",
      "Processes and frameworks almost always fail because they don't take into account the context of a given adoption. This is true even for processes that have had years of exposure in the field. I don't see for research can reasonably do better. \n",
      "It seems more literature on advises about how to apply RE in a particular domain.\n",
      "I suspect is no different to any other process to un-earth requirements. It would  not add much value.\n",
      "Blablabla \n",
      "it's important if one is searching for a good tool to do RE. I did this once and it was difficult.\n",
      "Not relevant in practical settings \n",
      "Understandability of requirements is not the biggest problem in RE.\n",
      "Not relevant to my company.\n",
      "The research is too academy oriented, it mixes so many aspects, I doubt that it can lead to practical results, other than the ones that can be obtained in a controlled environment with a very reduced set of requirements. \n"
     ]
    }
   ],
   "source": [
    "for elem in dfs['v_8780etseq']['reasoning']:\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Appendix: Vocab Exploration for Positive and Negative Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import preprocess_documents\n",
    "from gensim import corpora, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(544 unique tokens: ['align', 'case', 'chang', 'cumbersum', 'especi']...)\n"
     ]
    }
   ],
   "source": [
    "documents = list(dfs['v_8345etseq']['reasoning'])\n",
    "texts = preprocess_documents(documents)\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('requir', 44),\n",
       " ('import', 17),\n",
       " ('help', 17),\n",
       " ('method', 14),\n",
       " ('work', 13),\n",
       " ('project', 13),\n",
       " ('need', 13),\n",
       " ('understand', 11),\n",
       " ('time', 11),\n",
       " ('studi', 9),\n",
       " ('improv', 9),\n",
       " ('softwar', 8),\n",
       " ('process', 8),\n",
       " ('practic', 8),\n",
       " ('commun', 8),\n",
       " ('better', 8),\n",
       " ('think', 7),\n",
       " ('problem', 7),\n",
       " ('perform', 7),\n",
       " ('manag', 7),\n",
       " ('industri', 7),\n",
       " ('identifi', 7),\n",
       " ('good', 7),\n",
       " ('experi', 7),\n",
       " ('differ', 7),\n",
       " ('develop', 7),\n",
       " ('busi', 7),\n",
       " ('user', 6),\n",
       " ('traceabl', 6),\n",
       " ('system', 6),\n",
       " ('stakehold', 6),\n",
       " ('specif', 6),\n",
       " ('risk', 6),\n",
       " ('lot', 6),\n",
       " ('essenti', 6),\n",
       " ('critic', 6),\n",
       " ('wai', 5),\n",
       " ('result', 5),\n",
       " ('qualiti', 5),\n",
       " ('product', 5),\n",
       " ('model', 5),\n",
       " ('know', 5),\n",
       " ('interest', 5),\n",
       " ('impact', 5),\n",
       " ('goal', 5),\n",
       " ('exist', 5),\n",
       " ('especi', 5),\n",
       " ('environ', 5),\n",
       " ('chang', 5),\n",
       " ('case', 5),\n",
       " ('big', 5),\n",
       " ('base', 5),\n",
       " ('avoid', 5),\n",
       " ('agil', 5),\n",
       " ('want', 4),\n",
       " ('us', 4),\n",
       " ('test', 4),\n",
       " ('team', 4),\n",
       " ('task', 4),\n",
       " ('success', 4),\n",
       " ('standard', 4),\n",
       " ('spec', 4),\n",
       " ('solut', 4),\n",
       " ('secur', 4),\n",
       " ('right', 4),\n",
       " ('provid', 4),\n",
       " ('opinion', 4),\n",
       " ('learn', 4),\n",
       " ('lead', 4),\n",
       " ('issu', 4),\n",
       " ('futur', 4),\n",
       " ('function', 4),\n",
       " ('extrem', 4),\n",
       " ('engin', 4),\n",
       " ('design', 4),\n",
       " ('defin', 4),\n",
       " ('consid', 4),\n",
       " ('automat', 4),\n",
       " ('autom', 4),\n",
       " ('applic', 4),\n",
       " ('worth', 3),\n",
       " ('word', 3),\n",
       " ('valid', 3),\n",
       " ('uncertainti', 3),\n",
       " ('tool', 3),\n",
       " ('techniqu', 3),\n",
       " ('systemat', 3),\n",
       " ('sourc', 3),\n",
       " ('solv', 3),\n",
       " ('signific', 3),\n",
       " ('share', 3),\n",
       " ('research', 3),\n",
       " ('req', 3),\n",
       " ('relev', 3),\n",
       " ('reduc', 3),\n",
       " ('outcom', 3),\n",
       " ('order', 3),\n",
       " ('occur', 3),\n",
       " ('non', 3),\n",
       " ('make', 3),\n",
       " ('kei', 3),\n",
       " ('interview', 3),\n",
       " ('increas', 3),\n",
       " ('implement', 3),\n",
       " ('high', 3),\n",
       " ('great', 3),\n",
       " ('formal', 3),\n",
       " ('focu', 3),\n",
       " ('feedback', 3),\n",
       " ('factor', 3),\n",
       " ('establish', 3),\n",
       " ('effort', 3),\n",
       " ('eas', 3),\n",
       " ('domain', 3),\n",
       " ('difficult', 3),\n",
       " ('decis', 3),\n",
       " ('current', 3),\n",
       " ('crucial', 3),\n",
       " ('context', 3),\n",
       " ('conflict', 3),\n",
       " ('area', 3),\n",
       " ('approach', 3),\n",
       " ('adapt', 3),\n",
       " ('write', 2),\n",
       " ('translat', 2),\n",
       " ('topic', 2),\n",
       " ('todai', 2),\n",
       " ('term', 2),\n",
       " ('taken', 2),\n",
       " ('suitabl', 2),\n",
       " ('subject', 2),\n",
       " ('stratergi', 2),\n",
       " ('start', 2),\n",
       " ('spend', 2),\n",
       " ('specifi', 2),\n",
       " ('simpl', 2),\n",
       " ('significantli', 2),\n",
       " ('safeti', 2),\n",
       " ('runtim', 2),\n",
       " ('role', 2),\n",
       " ('remov', 2),\n",
       " ('regulatori', 2),\n",
       " ('question', 2),\n",
       " ('purpos', 2),\n",
       " ('prioriti', 2),\n",
       " ('predict', 2),\n",
       " ('practition', 2),\n",
       " ('possibl', 2),\n",
       " ('plan', 2),\n",
       " ('person', 2),\n",
       " ('parti', 2),\n",
       " ('natur', 2),\n",
       " ('miss', 2),\n",
       " ('measur', 2),\n",
       " ('major', 2),\n",
       " ('look', 2),\n",
       " ('littl', 2),\n",
       " ('like', 2),\n",
       " ('level', 2),\n",
       " ('larg', 2),\n",
       " ('languag', 2),\n",
       " ('knowledg', 2),\n",
       " ('kind', 2),\n",
       " ('ist', 2),\n",
       " ('interpret', 2),\n",
       " ('integr', 2),\n",
       " ('insight', 2),\n",
       " ('have', 2),\n",
       " ('happen', 2),\n",
       " ('hand', 2),\n",
       " ('gener', 2),\n",
       " ('gain', 2),\n",
       " ('follow', 2),\n",
       " ('field', 2),\n",
       " ('exchang', 2),\n",
       " ('ensur', 2),\n",
       " ('end', 2),\n",
       " ('effici', 2),\n",
       " ('effect', 2),\n",
       " ('drive', 2),\n",
       " ('dificult', 2),\n",
       " ('defect', 2),\n",
       " ('dai', 2),\n",
       " ('custom', 2),\n",
       " ('cultur', 2),\n",
       " ('contribut', 2),\n",
       " ('constraint', 2),\n",
       " ('complex', 2),\n",
       " ('compani', 2),\n",
       " ('common', 2),\n",
       " ('challeng', 2),\n",
       " ('captur', 2),\n",
       " ('biggest', 2),\n",
       " ('believ', 2),\n",
       " ('begin', 2),\n",
       " ('attent', 2),\n",
       " ('assess', 2),\n",
       " ('architectur', 2),\n",
       " ('appli', 2),\n",
       " ('analyst', 2),\n",
       " ('analysi', 2),\n",
       " ('analys', 2),\n",
       " ('ambigu', 2),\n",
       " ('allow', 2),\n",
       " ('align', 2),\n",
       " ('advanc', 2),\n",
       " ('address', 2),\n",
       " ('actual', 2),\n",
       " ('achiev', 2),\n",
       " ('überblick', 1),\n",
       " ('über', 1),\n",
       " ('yield', 1),\n",
       " ('year', 1),\n",
       " ('written', 1),\n",
       " ('visual', 1),\n",
       " ('vision', 1),\n",
       " ('visibl', 1),\n",
       " ('view', 1),\n",
       " ('verifi', 1),\n",
       " ('verif', 1),\n",
       " ('vendor', 1),\n",
       " ('vehicl', 1),\n",
       " ('valuabl', 1),\n",
       " ('util', 1),\n",
       " ('usuali', 1),\n",
       " ('usual', 1),\n",
       " ('upfront', 1),\n",
       " ('updat', 1),\n",
       " ('unstat', 1),\n",
       " ('unnecessari', 1),\n",
       " ('undo', 1),\n",
       " ('undergrad', 1),\n",
       " ('unanticip', 1),\n",
       " ('unambigu', 1),\n",
       " ('unadequ', 1),\n",
       " ('ubiqu', 1),\n",
       " ('typic', 1),\n",
       " ('type', 1),\n",
       " ('trough', 1),\n",
       " ('troubl', 1),\n",
       " ('transit', 1),\n",
       " ('transform', 1),\n",
       " ('track', 1),\n",
       " ('trace', 1),\n",
       " ('titl', 1),\n",
       " ('thing', 1),\n",
       " ('theme', 1),\n",
       " ('textual', 1),\n",
       " ('terminolog', 1),\n",
       " ('tension', 1),\n",
       " ('tend', 1),\n",
       " ('syse', 1),\n",
       " ('survei', 1),\n",
       " ('surpris', 1),\n",
       " ('sure', 1),\n",
       " ('support', 1),\n",
       " ('supplier', 1),\n",
       " ('struggl', 1),\n",
       " ('structur', 1),\n",
       " ('strongli', 1),\n",
       " ('strong', 1),\n",
       " ('strategi', 1),\n",
       " ('step', 1),\n",
       " ('state', 1),\n",
       " ('standardis', 1),\n",
       " ('specialist', 1),\n",
       " ('sound', 1),\n",
       " ('soss', 1),\n",
       " ('societi', 1),\n",
       " ('skim', 1),\n",
       " ('skill', 1),\n",
       " ('sichereen', 1),\n",
       " ('show', 1),\n",
       " ('shoulb', 1),\n",
       " ('shift', 1),\n",
       " ('sharpen', 1),\n",
       " ('shall', 1),\n",
       " ('sex', 1),\n",
       " ('seven', 1),\n",
       " ('setup', 1),\n",
       " ('seen', 1),\n",
       " ('save', 1),\n",
       " ('satisfi', 1),\n",
       " ('satisfact', 1),\n",
       " ('run', 1),\n",
       " ('rigour', 1),\n",
       " ('rework', 1),\n",
       " ('reuslt', 1),\n",
       " ('respect', 1),\n",
       " ('resourc', 1),\n",
       " ('request', 1),\n",
       " ('represent', 1),\n",
       " ('releas', 1),\n",
       " ('relat', 1),\n",
       " ('regul', 1),\n",
       " ('refin', 1),\n",
       " ('refactor', 1),\n",
       " ('recommend', 1),\n",
       " ('recogn', 1),\n",
       " ('recent', 1),\n",
       " ('reason', 1),\n",
       " ('real', 1),\n",
       " ('read', 1),\n",
       " ('re', 1),\n",
       " ('ration', 1),\n",
       " ('rare', 1),\n",
       " ('randomli', 1),\n",
       " ('random', 1),\n",
       " ('qualit', 1),\n",
       " ('purpuos', 1),\n",
       " ('prove', 1),\n",
       " ('proof', 1),\n",
       " ('profession', 1),\n",
       " ('produc', 1),\n",
       " ('probe', 1),\n",
       " ('probabl', 1),\n",
       " ('prioriz', 1),\n",
       " ('priorit', 1),\n",
       " ('prevent', 1),\n",
       " ('pressur', 1),\n",
       " ('potententi', 1),\n",
       " ('posit', 1),\n",
       " ('poorli', 1),\n",
       " ('point', 1),\n",
       " ('pm', 1),\n",
       " ('phd', 1),\n",
       " ('persona', 1),\n",
       " ('percept', 1),\n",
       " ('peopl', 1),\n",
       " ('peer', 1),\n",
       " ('particular', 1),\n",
       " ('part', 1),\n",
       " ('paradigm', 1),\n",
       " ('pai', 1),\n",
       " ('owner', 1),\n",
       " ('overview', 1),\n",
       " ('outdat', 1),\n",
       " ('organis', 1),\n",
       " ('onlin', 1),\n",
       " ('old', 1),\n",
       " ('number', 1),\n",
       " ('nfr', 1),\n",
       " ('new', 1),\n",
       " ('neglect', 1),\n",
       " ('necessari', 1),\n",
       " ('necesari', 1),\n",
       " ('nearli', 1),\n",
       " ('multi', 1),\n",
       " ('monitor', 1),\n",
       " ('monei', 1),\n",
       " ('misunderstand', 1),\n",
       " ('mistak', 1),\n",
       " ('misintrerpret', 1),\n",
       " ('minut', 1),\n",
       " ('men', 1),\n",
       " ('mean', 1),\n",
       " ('matur', 1),\n",
       " ('massiv', 1),\n",
       " ('market', 1),\n",
       " ('marker', 1),\n",
       " ('map', 1),\n",
       " ('maintain', 1),\n",
       " ('love', 1),\n",
       " ('lock', 1),\n",
       " ('live', 1),\n",
       " ('literatur', 1),\n",
       " ('link', 1),\n",
       " ('limit', 1),\n",
       " ('life', 1),\n",
       " ('lesson', 1),\n",
       " ('legal', 1),\n",
       " ('left', 1),\n",
       " ('late', 1),\n",
       " ('job', 1),\n",
       " ('item', 1),\n",
       " ('isol', 1),\n",
       " ('introduc', 1),\n",
       " ('interviewe', 1),\n",
       " ('interoper', 1),\n",
       " ('instal', 1),\n",
       " ('insidi', 1),\n",
       " ('innov', 1),\n",
       " ('initi', 1),\n",
       " ('inform', 1),\n",
       " ('influenc', 1),\n",
       " ('increment', 1),\n",
       " ('inconsit', 1),\n",
       " ('inconsist', 1),\n",
       " ('includ', 1),\n",
       " ('imposs', 1),\n",
       " ('illeg', 1),\n",
       " ('ignor', 1),\n",
       " ('ideal', 1),\n",
       " ('highli', 1),\n",
       " ('highest', 1),\n",
       " ('haven', 1),\n",
       " ('harm', 1),\n",
       " ('hardwar', 1),\n",
       " ('hard', 1),\n",
       " ('guarante', 1),\n",
       " ('grow', 1),\n",
       " ('group', 1),\n",
       " ('green', 1),\n",
       " ('gover', 1),\n",
       " ('gap', 1),\n",
       " ('furthermor', 1),\n",
       " ('fundament', 1),\n",
       " ('frequent', 1),\n",
       " ('frame', 1),\n",
       " ('foundat', 1),\n",
       " ('format', 1),\n",
       " ('forc', 1),\n",
       " ('flown', 1),\n",
       " ('fit', 1),\n",
       " ('final', 1),\n",
       " ('feel', 1),\n",
       " ('featur', 1),\n",
       " ('fast', 1),\n",
       " ('fail', 1),\n",
       " ('face', 1),\n",
       " ('extract', 1),\n",
       " ('extens', 1),\n",
       " ('expos', 1),\n",
       " ('expertic', 1),\n",
       " ('excel', 1),\n",
       " ('exampl', 1),\n",
       " ('evolv', 1),\n",
       " ('eventu', 1),\n",
       " ('erhalten', 1),\n",
       " ('enabl', 1),\n",
       " ('elicit', 1),\n",
       " ('elect', 1),\n",
       " ('einen', 1),\n",
       " ('easili', 1),\n",
       " ('easi', 1),\n",
       " ('earn', 1),\n",
       " ('earli', 1),\n",
       " ('dynam', 1),\n",
       " ('driven', 1),\n",
       " ('drastic', 1),\n",
       " ('doubl', 1),\n",
       " ('door', 1),\n",
       " ('document', 1),\n",
       " ('diversifi', 1),\n",
       " ('discuss', 1),\n",
       " ('disciplinari', 1),\n",
       " ('dilemma', 1),\n",
       " ('die', 1),\n",
       " ('determin', 1),\n",
       " ('detail', 1),\n",
       " ('despit', 1),\n",
       " ('desir', 1),\n",
       " ('deserv', 1),\n",
       " ('descriptioni', 1),\n",
       " ('dependeci', 1),\n",
       " ('depend', 1),\n",
       " ('demand', 1),\n",
       " ('deliveri', 1),\n",
       " ('deliv', 1),\n",
       " ('definit', 1),\n",
       " ('decreas', 1),\n",
       " ('deal', 1),\n",
       " ('daili', 1),\n",
       " ('cumbersum', 1),\n",
       " ('criticl', 1),\n",
       " ('creativ', 1),\n",
       " ('creat', 1),\n",
       " ('coupl', 1),\n",
       " ('correl', 1),\n",
       " ('convers', 1),\n",
       " ('contradictori', 1),\n",
       " ('constantli', 1),\n",
       " ('constant', 1),\n",
       " ('consist', 1),\n",
       " ('connect', 1),\n",
       " ('confid', 1),\n",
       " ('concern', 1),\n",
       " ('concept', 1),\n",
       " ('compris', 1),\n",
       " ('comprehens', 1),\n",
       " ('completl', 1),\n",
       " ('complet', 1),\n",
       " ('complcat', 1),\n",
       " ('commonli', 1),\n",
       " ('come', 1),\n",
       " ('combin', 1),\n",
       " ('collabor', 1),\n",
       " ('coincid', 1),\n",
       " ('code', 1),\n",
       " ('close', 1),\n",
       " ('client', 1),\n",
       " ('classic', 1),\n",
       " ('class', 1),\n",
       " ('cinnect', 1),\n",
       " ('check', 1),\n",
       " ('characterist', 1),\n",
       " ('challang', 1),\n",
       " ('caus', 1),\n",
       " ('caught', 1),\n",
       " ('categori', 1),\n",
       " ('carefulli', 1),\n",
       " ('capac', 1),\n",
       " ('build', 1),\n",
       " ('budget', 1),\n",
       " ('broadli', 1),\n",
       " ('bridg', 1),\n",
       " ('boundari', 1),\n",
       " ('boost', 1),\n",
       " ('bill', 1),\n",
       " ('beschriebenen', 1),\n",
       " ('benefit', 1),\n",
       " ('benchmark', 1),\n",
       " ('behaviour', 1),\n",
       " ('basi', 1),\n",
       " ('balanc', 1),\n",
       " ('badli', 1),\n",
       " ('ba', 1),\n",
       " ('awar', 1),\n",
       " ('awai', 1),\n",
       " ('autonom', 1),\n",
       " ('assumpt', 1),\n",
       " ('aspect', 1),\n",
       " ('asid', 1),\n",
       " ('artifact', 1),\n",
       " ('articul', 1),\n",
       " ('articl', 1),\n",
       " ('aren', 1),\n",
       " ('architect', 1),\n",
       " ('approch', 1),\n",
       " ('appreci', 1),\n",
       " ('appear', 1),\n",
       " ('anysi', 1),\n",
       " ('antecip', 1),\n",
       " ('analyz', 1),\n",
       " ('amount', 1),\n",
       " ('algorithm', 1),\n",
       " ('ag', 1),\n",
       " ('affect', 1),\n",
       " ('adress', 1),\n",
       " ('activ', 1),\n",
       " ('action', 1),\n",
       " ('accord', 1),\n",
       " ('access', 1),\n",
       " ('ablaüf', 1)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a list of word stems, sorted by frequency in the answers DESC\n",
    "sorted([(k,v) for k,v in Counter([elem[x] for elem in texts for x in range(len(elem))]).items()], \n",
    "       key=lambda x:(x[1],x[0]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(462 unique tokens: ['care', 'develop', 'person', 'specif', 'us']...)\n"
     ]
    }
   ],
   "source": [
    "documents2 = list(dfs['v_8780etseq']['reasoning'])\n",
    "texts2 = preprocess_documents(documents2)\n",
    "dictionary2 = corpora.Dictionary(texts2)\n",
    "print(dictionary2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('requir', 18),\n",
       " ('work', 12),\n",
       " ('need', 11),\n",
       " ('understand', 10),\n",
       " ('us', 9),\n",
       " ('specif', 9),\n",
       " ('project', 9),\n",
       " ('industri', 9),\n",
       " ('research', 8),\n",
       " ('problem', 8),\n",
       " ('model', 8),\n",
       " ('import', 8),\n",
       " ('approach', 8),\n",
       " ('softwar', 7),\n",
       " ('relev', 7),\n",
       " ('person', 7),\n",
       " ('know', 7),\n",
       " ('interest', 7),\n",
       " ('domain', 7),\n",
       " ('differ', 7),\n",
       " ('sure', 6),\n",
       " ('process', 6),\n",
       " ('practic', 6),\n",
       " ('method', 6),\n",
       " ('manag', 6),\n",
       " ('engin', 6),\n",
       " ('appli', 6),\n",
       " ('tool', 5),\n",
       " ('result', 5),\n",
       " ('real', 5),\n",
       " ('product', 5),\n",
       " ('languag', 5),\n",
       " ('high', 5),\n",
       " ('good', 5),\n",
       " ('experi', 5),\n",
       " ('effort', 5),\n",
       " ('compani', 5),\n",
       " ('better', 5),\n",
       " ('applic', 5),\n",
       " ('wai', 4),\n",
       " ('topic', 4),\n",
       " ('think', 4),\n",
       " ('set', 4),\n",
       " ('notat', 4),\n",
       " ('help', 4),\n",
       " ('goal', 4),\n",
       " ('environ', 4),\n",
       " ('document', 4),\n",
       " ('benefit', 4),\n",
       " ('avail', 4),\n",
       " ('analyst', 4),\n",
       " ('valu', 3),\n",
       " ('usual', 3),\n",
       " ('uncertainti', 3),\n",
       " ('time', 3),\n",
       " ('technolog', 3),\n",
       " ('system', 3),\n",
       " ('studi', 3),\n",
       " ('special', 3),\n",
       " ('sound', 3),\n",
       " ('solut', 3),\n",
       " ('small', 3),\n",
       " ('prefer', 3),\n",
       " ('place', 3),\n",
       " ('particular', 3),\n",
       " ('paper', 3),\n",
       " ('opinion', 3),\n",
       " ('level', 3),\n",
       " ('impact', 3),\n",
       " ('idea', 3),\n",
       " ('human', 3),\n",
       " ('exist', 3),\n",
       " ('easi', 3),\n",
       " ('design', 3),\n",
       " ('data', 3),\n",
       " ('consist', 3),\n",
       " ('consid', 3),\n",
       " ('complex', 3),\n",
       " ('clear', 3),\n",
       " ('chang', 3),\n",
       " ('case', 3),\n",
       " ('brainstorm', 3),\n",
       " ('base', 3),\n",
       " ('analysi', 3),\n",
       " ('wrong', 2),\n",
       " ('worthwil', 2),\n",
       " ('world', 2),\n",
       " ('valid', 2),\n",
       " ('traceabl', 2),\n",
       " ('thing', 2),\n",
       " ('test', 2),\n",
       " ('technic', 2),\n",
       " ('subject', 2),\n",
       " ('student', 2),\n",
       " ('structur', 2),\n",
       " ('standard', 2),\n",
       " ('specifii', 2),\n",
       " ('sorri', 2),\n",
       " ('skill', 2),\n",
       " ('simpl', 2),\n",
       " ('resourc', 2),\n",
       " ('reduc', 2),\n",
       " ('recommend', 2),\n",
       " ('reader', 2),\n",
       " ('rate', 2),\n",
       " ('predict', 2),\n",
       " ('practition', 2),\n",
       " ('possibl', 2),\n",
       " ('piec', 2),\n",
       " ('perform', 2),\n",
       " ('peopl', 2),\n",
       " ('outcom', 2),\n",
       " ('order', 2),\n",
       " ('option', 2),\n",
       " ('nfr', 2),\n",
       " ('mean', 2),\n",
       " ('lot', 2),\n",
       " ('look', 2),\n",
       " ('like', 2),\n",
       " ('learn', 2),\n",
       " ('lead', 2),\n",
       " ('justifi', 2),\n",
       " ('involv', 2),\n",
       " ('investig', 2),\n",
       " ('integr', 2),\n",
       " ('improv', 2),\n",
       " ('hard', 2),\n",
       " ('given', 2),\n",
       " ('gener', 2),\n",
       " ('formal', 2),\n",
       " ('field', 2),\n",
       " ('feedback', 2),\n",
       " ('featur', 2),\n",
       " ('extract', 2),\n",
       " ('effect', 2),\n",
       " ('dont', 2),\n",
       " ('difficult', 2),\n",
       " ('diagram', 2),\n",
       " ('develop', 2),\n",
       " ('der', 2),\n",
       " ('defin', 2),\n",
       " ('custom', 2),\n",
       " ('creat', 2),\n",
       " ('context', 2),\n",
       " ('conflict', 2),\n",
       " ('commun', 2),\n",
       " ('come', 2),\n",
       " ('big', 2),\n",
       " ('ba', 2),\n",
       " ('assess', 2),\n",
       " ('answer', 2),\n",
       " ('agil', 2),\n",
       " ('affect', 2),\n",
       " ('advanc', 2),\n",
       " ('yei', 1),\n",
       " ('year', 1),\n",
       " ('ye', 1),\n",
       " ('wsjf', 1),\n",
       " ('writer', 1),\n",
       " ('worthwhil', 1),\n",
       " ('wors', 1),\n",
       " ('word', 1),\n",
       " ('wocabulari', 1),\n",
       " ('wider', 1),\n",
       " ('whatsoev', 1),\n",
       " ('web', 1),\n",
       " ('wast', 1),\n",
       " ('vote', 1),\n",
       " ('view', 1),\n",
       " ('variabl', 1),\n",
       " ('valuabl', 1),\n",
       " ('util', 1),\n",
       " ('user', 1),\n",
       " ('usabl', 1),\n",
       " ('uninterest', 1),\n",
       " ('understood', 1),\n",
       " ('unclear', 1),\n",
       " ('trust', 1),\n",
       " ('true', 1),\n",
       " ('translat', 1),\n",
       " ('train', 1),\n",
       " ('thought', 1),\n",
       " ('theoret', 1),\n",
       " ('teniou', 1),\n",
       " ('techniqu', 1),\n",
       " ('talk', 1),\n",
       " ('suspect', 1),\n",
       " ('survei', 1),\n",
       " ('support', 1),\n",
       " ('suppli', 1),\n",
       " ('suffici', 1),\n",
       " ('struggl', 1),\n",
       " ('store', 1),\n",
       " ('spend', 1),\n",
       " ('specialist', 1),\n",
       " ('specialis', 1),\n",
       " ('solv', 1),\n",
       " ('societi', 1),\n",
       " ('social', 1),\n",
       " ('simplist', 1),\n",
       " ('signific', 1),\n",
       " ('short', 1),\n",
       " ('session', 1),\n",
       " ('senseful', 1),\n",
       " ('sens', 1),\n",
       " ('self', 1),\n",
       " ('select', 1),\n",
       " ('sector', 1),\n",
       " ('search', 1),\n",
       " ('scenario', 1),\n",
       " ('satisfi', 1),\n",
       " ('safeti', 1),\n",
       " ('robust', 1),\n",
       " ('risk', 1),\n",
       " ('right', 1),\n",
       " ('review', 1),\n",
       " ('reusabl', 1),\n",
       " ('return', 1),\n",
       " ('restrict', 1),\n",
       " ('req', 1),\n",
       " ('repres', 1),\n",
       " ('reliabl', 1),\n",
       " ('relat', 1),\n",
       " ('rel', 1),\n",
       " ('rehabilit', 1),\n",
       " ('regul', 1),\n",
       " ('refer', 1),\n",
       " ('receiv', 1),\n",
       " ('reason', 1),\n",
       " ('realiti', 1),\n",
       " ('read', 1),\n",
       " ('re', 1),\n",
       " ('rare', 1),\n",
       " ('rapid', 1),\n",
       " ('question', 1),\n",
       " ('quantit', 1),\n",
       " ('punkt', 1),\n",
       " ('provid', 1),\n",
       " ('prosa', 1),\n",
       " ('promis', 1),\n",
       " ('profession', 1),\n",
       " ('probrem', 1),\n",
       " ('probabl', 1),\n",
       " ('prioriz', 1),\n",
       " ('prioriti', 1),\n",
       " ('priorit', 1),\n",
       " ('pretti', 1),\n",
       " ('prerequisit', 1),\n",
       " ('praction', 1),\n",
       " ('polut', 1),\n",
       " ('pointless', 1),\n",
       " ('phenomenon', 1),\n",
       " ('phd', 1),\n",
       " ('persuad', 1),\n",
       " ('perspect', 1),\n",
       " ('peop', 1),\n",
       " ('pattern', 1),\n",
       " ('part', 1),\n",
       " ('page', 1),\n",
       " ('oversight', 1),\n",
       " ('overkil', 1),\n",
       " ('output', 1),\n",
       " ('origin', 1),\n",
       " ('orient', 1),\n",
       " ('organ', 1),\n",
       " ('orchestr', 1),\n",
       " ('oper', 1),\n",
       " ('on', 1),\n",
       " ('old', 1),\n",
       " ('oinli', 1),\n",
       " ('ofen', 1),\n",
       " ('obtain', 1),\n",
       " ('obscur', 1),\n",
       " ('nto', 1),\n",
       " ('novic', 1),\n",
       " ('normal', 1),\n",
       " ('nicht', 1),\n",
       " ('nfrr', 1),\n",
       " ('new', 1),\n",
       " ('necessarili', 1),\n",
       " ('necessari', 1),\n",
       " ('natur', 1),\n",
       " ('narrow', 1),\n",
       " ('multitud', 1),\n",
       " ('moment', 1),\n",
       " ('modul', 1),\n",
       " ('mix', 1),\n",
       " ('misled', 1),\n",
       " ('mind', 1),\n",
       " ('metric', 1),\n",
       " ('met', 1),\n",
       " ('meet', 1),\n",
       " ('mechan', 1),\n",
       " ('meaningfulli', 1),\n",
       " ('matter', 1),\n",
       " ('major', 1),\n",
       " ('magnitud', 1),\n",
       " ('machin', 1),\n",
       " ('lower', 1),\n",
       " ('loop', 1),\n",
       " ('logic', 1),\n",
       " ('littl', 1),\n",
       " ('literatur', 1),\n",
       " ('link', 1),\n",
       " ('limit', 1),\n",
       " ('life', 1),\n",
       " ('let', 1),\n",
       " ('land', 1),\n",
       " ('lab', 1),\n",
       " ('knowledg', 1),\n",
       " ('keyword', 1),\n",
       " ('kenntni', 1),\n",
       " ('job', 1),\n",
       " ('ist', 1),\n",
       " ('intuit', 1),\n",
       " ('interact', 1),\n",
       " ('inspect', 1),\n",
       " ('input', 1),\n",
       " ('initi', 1),\n",
       " ('impract', 1),\n",
       " ('importat', 1),\n",
       " ('implement', 1),\n",
       " ('imagin', 1),\n",
       " ('imag', 1),\n",
       " ('identitfi', 1),\n",
       " ('identifi', 1),\n",
       " ('huge', 1),\n",
       " ('histori', 1),\n",
       " ('hinder', 1),\n",
       " ('highli', 1),\n",
       " ('higher', 1),\n",
       " ('hierarch', 1),\n",
       " ('hierarc', 1),\n",
       " ('heard', 1),\n",
       " ('head', 1),\n",
       " ('harm', 1),\n",
       " ('guess', 1),\n",
       " ('greater', 1),\n",
       " ('goe', 1),\n",
       " ('go', 1),\n",
       " ('give', 1),\n",
       " ('genral', 1),\n",
       " ('geht', 1),\n",
       " ('furthermor', 1),\n",
       " ('frustrat', 1),\n",
       " ('frequent', 1),\n",
       " ('framework', 1),\n",
       " ('form', 1),\n",
       " ('focu', 1),\n",
       " ('fly', 1),\n",
       " ('fluffi', 1),\n",
       " ('finish', 1),\n",
       " ('fast', 1),\n",
       " ('far', 1),\n",
       " ('fail', 1),\n",
       " ('extrem', 1),\n",
       " ('extent', 1),\n",
       " ('extens', 1),\n",
       " ('exposur', 1),\n",
       " ('explain', 1),\n",
       " ('expertis', 1),\n",
       " ('expert', 1),\n",
       " ('expect', 1),\n",
       " ('exchang', 1),\n",
       " ('evolut', 1),\n",
       " ('eventu', 1),\n",
       " ('essenti', 1),\n",
       " ('entscheidend', 1),\n",
       " ('elicit', 1),\n",
       " ('ein', 1),\n",
       " ('eher', 1),\n",
       " ('efect', 1),\n",
       " ('educ', 1),\n",
       " ('econom', 1),\n",
       " ('easiest', 1),\n",
       " ('earth', 1),\n",
       " ('dynam', 1),\n",
       " ('driven', 1),\n",
       " ('doubt', 1),\n",
       " ('distract', 1),\n",
       " ('discov', 1),\n",
       " ('direct', 1),\n",
       " ('diificult', 1),\n",
       " ('diag', 1),\n",
       " ('detail', 1),\n",
       " ('depend', 1),\n",
       " ('deliv', 1),\n",
       " ('defect', 1),\n",
       " ('dedic', 1),\n",
       " ('decreas', 1),\n",
       " ('decis', 1),\n",
       " ('decid', 1),\n",
       " ('date', 1),\n",
       " ('daili', 1),\n",
       " ('current', 1),\n",
       " ('cross', 1),\n",
       " ('creativ', 1),\n",
       " ('corpor', 1),\n",
       " ('convinc', 1),\n",
       " ('control', 1),\n",
       " ('contribuy', 1),\n",
       " ('contini', 1),\n",
       " ('consider', 1),\n",
       " ('confus', 1),\n",
       " ('conclus', 1),\n",
       " ('compar', 1),\n",
       " ('common', 1),\n",
       " ('commerci', 1),\n",
       " ('clip', 1),\n",
       " ('clearli', 1),\n",
       " ('check', 1),\n",
       " ('chain', 1),\n",
       " ('certain', 1),\n",
       " ('care', 1),\n",
       " ('capac', 1),\n",
       " ('capabl', 1),\n",
       " ('busi', 1),\n",
       " ('bug', 1),\n",
       " ('break', 1),\n",
       " ('blablabla', 1),\n",
       " ('bit', 1),\n",
       " ('biggest', 1),\n",
       " ('best', 1),\n",
       " ('benefici', 1),\n",
       " ('believ', 1),\n",
       " ('be', 1),\n",
       " ('bang', 1),\n",
       " ('bad', 1),\n",
       " ('automot', 1),\n",
       " ('automat', 1),\n",
       " ('autom', 1),\n",
       " ('attitud', 1),\n",
       " ('attent', 1),\n",
       " ('attempt', 1),\n",
       " ('assumpt', 1),\n",
       " ('assum', 1),\n",
       " ('assert', 1),\n",
       " ('aspect', 1),\n",
       " ('artifact', 1),\n",
       " ('area', 1),\n",
       " ('architectur', 1),\n",
       " ('architect', 1),\n",
       " ('appear', 1),\n",
       " ('app', 1),\n",
       " ('anwendungsbereich', 1),\n",
       " ('analyz', 1),\n",
       " ('analyt', 1),\n",
       " ('ambigu', 1),\n",
       " ('align', 1),\n",
       " ('algorithm', 1),\n",
       " ('ai', 1),\n",
       " ('advis', 1),\n",
       " ('adopt', 1),\n",
       " ('addition', 1),\n",
       " ('addit', 1),\n",
       " ('add', 1),\n",
       " ('adapt', 1),\n",
       " ('actual', 1),\n",
       " ('activ', 1),\n",
       " ('account', 1),\n",
       " ('academi', 1),\n",
       " ('abl', 1)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(k,v) for k,v in Counter([elem[x] for elem in texts2 for x in range(len(elem))]).items()], \n",
    "       key=lambda x:(x[1],x[0]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tum]",
   "language": "python",
   "name": "conda-env-tum-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
