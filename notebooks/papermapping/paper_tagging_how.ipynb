{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../../data/papersummaries_cleaned.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](tagging_how.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: The Science category is deliberately not split into validation and evaluation. These terms are not very intuitive and respondents will hardly have realized any such distinction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_tag(level_1, level_2, level_3, summary):\n",
    "    tags = []\n",
    "    for tag in level_2:\n",
    "        if any([re.search(keyword, summary) for keyword in level_3[tag]]):\n",
    "            tags.append(level_1+tag)\n",
    "    return tags\n",
    "\n",
    "\n",
    "def assign_engineering(summary):\n",
    "    level_1 = ':engineering'\n",
    "    \n",
    "    level_2 = [':analysis', ':technology', ':method']\n",
    "    \n",
    "    level_3 = {':analysis':\n",
    "                   ['A set of metrics']\n",
    "               , \n",
    "               ':technology':\n",
    "                   ['A tool', 'A solution', 'A model', \n",
    "                    'A taxonomy', 'An ontology', 'A (:?modell?ing |specification )language', \n",
    "                    'A template', '[Aa] blueprint', 'A (formal )?framework']\n",
    "               , \n",
    "               ':method':\n",
    "                   ['A method', 'A process', 'A.{,15}technique', 'training program']\n",
    "               }\n",
    "    \n",
    "    return assign_tag(level_1, level_2, level_3, summary)\n",
    "\n",
    "\n",
    "def assign_science(summary):\n",
    "    level_1 = ':science'\n",
    "    \n",
    "    level_2 = [':observation', ':intervention', ':interrogation']\n",
    "    \n",
    "    level_3 = {':observation':\n",
    "                   ['(:?(:?multi.)?case|field) study',\n",
    "                    '(:?data.|document.)driven study',\n",
    "                    'industrial evaluation', 'An analysis']\n",
    "               , \n",
    "               ':intervention':\n",
    "                   ['experiment(?:s|\\s)', \n",
    "                    'project-based study', 'workshop-based industrial study', \n",
    "                    'action research']\n",
    "               ,\n",
    "               ':interrogation':\n",
    "                   ['interview-based study|study based on.{,30}interviews', \n",
    "                    'questionnaire', '(?<!literature )(?:online.)?survey']\n",
    "               }\n",
    "    \n",
    "    return assign_tag(level_1, level_2, level_3, summary)\n",
    "\n",
    "\n",
    "def assign_perspective(summary):\n",
    "    level_1 = ':perspective'\n",
    "    \n",
    "    level_2 = [':philosophy', ':opinion', ':experience', ':review']\n",
    "    \n",
    "    level_3 = {':philosophy':\n",
    "                   ['conceptual framework']\n",
    "               , \n",
    "               ':opinion':\n",
    "                   ['A discussion', '\\svision', 'roadmap\\s']\n",
    "               , \n",
    "               ':experience':\n",
    "                   ['experience report']\n",
    "               ,\n",
    "               ':review':\n",
    "                   ['literature (:?survey|study|review)',\n",
    "                    'state of the art report']\n",
    "               } \n",
    "    \n",
    "    return assign_tag(level_1, level_2, level_3, summary)\n",
    "\n",
    "\n",
    "def assign_all(summary):\n",
    "    tags = ['how'+ x for x in \n",
    "            (assign_engineering(summary) \n",
    "             + assign_science(summary)\n",
    "             + assign_perspective(summary))]\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: As of now, the third level isn't explicitly represented in the tags. That's unfortunate especially for the distinction experiment/survey (which I'd expect to be evaluated differently). I'd suggest we refine tags using a separate function (after the initial tag assignment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['how'] = [assign_all(x) for x in df.PaperSummary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PaperID</th>\n",
       "      <th>PaperSummary</th>\n",
       "      <th>how</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A method for automatically recovering software...</td>\n",
       "      <td>[how:engineering:method]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A set of two techniques for improving the qual...</td>\n",
       "      <td>[how:engineering:method]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A case study on evaluating a given technique f...</td>\n",
       "      <td>[how:science:observation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>An experience report on the development of a m...</td>\n",
       "      <td>[how:perspective:experience]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>A document-driven study on the relevancy of cl...</td>\n",
       "      <td>[how:science:observation]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PaperID                                       PaperSummary  \\\n",
       "0        1  A method for automatically recovering software...   \n",
       "1        2  A set of two techniques for improving the qual...   \n",
       "2        3  A case study on evaluating a given technique f...   \n",
       "3        4  An experience report on the development of a m...   \n",
       "4        5  A document-driven study on the relevancy of cl...   \n",
       "\n",
       "                            how  \n",
       "0      [how:engineering:method]  \n",
       "1      [how:engineering:method]  \n",
       "2     [how:science:observation]  \n",
       "3  [how:perspective:experience]  \n",
       "4     [how:science:observation]  "
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summaries without tags?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x[0], x[1][1], x[1][2]) for x in df.iterrows() if len(x[1][2]) < 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summaries with multiple tags? (to check whether they're okay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(71,\n",
       "  'A study based on experiments with students and a case study on the possible benefits of considering existing services and their alignment with requirements at a very early stage in order to exploit the desired benefits of reuse in service-oriented architectures',\n",
       "  ['how:science:observation', 'how:science:intervention']),\n",
       " (207,\n",
       "  'A literature survey on requirements elicitation techniques and a roadmap of research in order to improve the elicitation of tacit knowledge',\n",
       "  ['how:perspective:opinion', 'how:perspective:review']),\n",
       " (368,\n",
       "  'A set of two empirical studies (online survey to practitioners and experiment with students) on the creation and use of software requirement specifications in companies and the impact of their quality in subsequent development activities.',\n",
       "  ['how:science:intervention', 'how:science:interrogation']),\n",
       " (395,\n",
       "  'A literature study on specific threats to validity in controlled experiments with student participants and on mitigation strategies for these threats.',\n",
       "  ['how:science:intervention', 'how:perspective:review']),\n",
       " (402,\n",
       "  'A study based on interviews with practitioners and a literature review for building a body of knowledge for traceability in order to assist engineers how to implement traceability in a project.',\n",
       "  ['how:science:interrogation', 'how:perspective:review'])]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x[0], x[1][1], x[1][2]) for x in df.iterrows() if len(x[1][2]) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PaperID</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>how:engineering:method</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>how:engineering:method</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>how:science:observation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>how:perspective:experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>how:science:observation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PaperID                         Tag\n",
       "0       1      how:engineering:method\n",
       "1       2      how:engineering:method\n",
       "2       3     how:science:observation\n",
       "3       4  how:perspective:experience\n",
       "4       5     how:science:observation"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longform_tags = pd.DataFrame(columns=['PaperID', 'Tag'])\n",
    "for row in df.iterrows():\n",
    "    longform_tags = longform_tags.append(\n",
    "        pd.DataFrame({'PaperID':list(len(row[1][2])*[row[1][0]]), 'Tag':row[1][2]}))\n",
    "longform_tags = longform_tags.reset_index().drop('index', axis=1)\n",
    "longform_tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PaperID</th>\n",
       "      <th>Tag</th>\n",
       "      <th>level_1</th>\n",
       "      <th>level_2</th>\n",
       "      <th>level_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>how:engineering:method</td>\n",
       "      <td>how</td>\n",
       "      <td>engineering</td>\n",
       "      <td>method</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>how:engineering:method</td>\n",
       "      <td>how</td>\n",
       "      <td>engineering</td>\n",
       "      <td>method</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>how:science:observation</td>\n",
       "      <td>how</td>\n",
       "      <td>science</td>\n",
       "      <td>observation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>how:perspective:experience</td>\n",
       "      <td>how</td>\n",
       "      <td>perspective</td>\n",
       "      <td>experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>how:science:observation</td>\n",
       "      <td>how</td>\n",
       "      <td>science</td>\n",
       "      <td>observation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PaperID                         Tag level_1      level_2      level_3\n",
       "0       1      how:engineering:method     how  engineering       method\n",
       "1       2      how:engineering:method     how  engineering       method\n",
       "2       3     how:science:observation     how      science  observation\n",
       "3       4  how:perspective:experience     how  perspective   experience\n",
       "4       5     how:science:observation     how      science  observation"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_three_levels = list(zip(*[x.split(':') for x in longform_tags.Tag]))\n",
    "longform_tags['level_1'] = tags_three_levels[0]\n",
    "longform_tags['level_2'] = tags_three_levels[1]\n",
    "longform_tags['level_3'] = tags_three_levels[2]\n",
    "longform_tags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: some papers appear multiple times in the counts (here: twice at max) since some papers receive multiple tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>PaperID</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level_1</th>\n",
       "      <th>level_2</th>\n",
       "      <th>level_3</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">how</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">engineering</th>\n",
       "      <th>analysis</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <td>162</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technology</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">perspective</th>\n",
       "      <th>experience</th>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opinion</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>philosophy</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">science</th>\n",
       "      <th>interrogation</th>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intervention</th>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>observation</th>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   PaperID  Tag\n",
       "level_1 level_2     level_3                    \n",
       "how     engineering analysis             1    1\n",
       "                    method             162  162\n",
       "                    technology          52   52\n",
       "        perspective experience          38   38\n",
       "                    opinion             11   11\n",
       "                    philosophy           1    1\n",
       "                    review              14   14\n",
       "        science     interrogation       43   43\n",
       "                    intervention        37   37\n",
       "                    observation         81   81"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longform_tags.groupby(['level_1', 'level_2', 'level_3']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "#longform_tags.merge(df[['PaperID', 'PaperSummary']]\n",
    "#                   ).to_csv('../../analysis/papersummaries_tagged_how.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With whom?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in df.PaperSummary if re.search('with students and practitioners', x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in df.PaperSummary if re.search('with practitioners and students', x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in df.PaperSummary if re.search('with students', x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in df.PaperSummary if re.search('with practitioners', x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in df.PaperSummary if re.search('with crowd workers', x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in df.PaperSummary if re.search('academics', x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in df.PaperSummary if re.search('researchers', x)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The End."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tum]",
   "language": "python",
   "name": "conda-env-tum-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
